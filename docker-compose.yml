services:
  # Text Analyzer Service
  textanalyzer:
    image: docutag-textanalyzer:latest
    build:
      context: .
      dockerfile: apps/textanalyzer/Dockerfile
    container_name: docutag-textanalyzer
    labels:
      app: docutag
      app.type: backend
    ports:
      - "9082:8080"
    environment:
      - PORT=8080
      # PostgreSQL configuration
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_USER=docutag
      - DB_PASSWORD=docutag_dev_pass
      - DB_NAME=textanalyzer_db
      - USE_OLLAMA=true
      - OLLAMA_URL=http://100.64.0.2:11434
      - OLLAMA_MODEL=gemma3:4b
      - REDIS_ADDR=redis:6379
      - WORKER_CONCURRENCY=5
      - TEMPO_ENDPOINT=tempo:4317
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 10s
    networks:
      - docutag-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      loki:
        condition: service_started
      tempo:
        condition: service_started

  # Scraper Service
  scraper:
    image: docutag-scraper:latest
    build:
      context: .
      dockerfile: apps/scraper/Dockerfile
    container_name: docutag-scraper
    labels:
      app: docutag
      app.type: backend
    ports:
      - "9081:8080"
    environment:
      - PORT=8080
      - STORAGE_BASE_PATH=/app/storage
      - OLLAMA_URL=http://100.64.0.2:11434
      - OLLAMA_MODEL=gemma3:4b
      - TEMPO_ENDPOINT=tempo:4317
      # PostgreSQL configuration
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_USER=docutag
      - DB_PASSWORD=docutag_dev_pass
      - DB_NAME=scraper_db
      # - OLLAMA_VISION_MODEL=gemma3:4b
      # - MAX_IMAGES=20  # Maximum number of images to download per scrape (0 = unlimited)
    volumes:
      - scraper-storage:/app/storage
    command: [
      "./scraper-api",
    ]
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    networks:
      - docutag-network
    depends_on:
      postgres:
        condition: service_healthy
      loki:
        condition: service_started
      tempo:
        condition: service_started

  # Controller Service
  controller:
    image: docutag-controller:latest
    build:
      context: .
      dockerfile: apps/controller/Dockerfile
    container_name: docutag-controller
    labels:
      app: docutag
      app.type: backend
    ports:
      - "9080:8080"
    environment:
      # Service URLs - internal network references
      - SCRAPER_BASE_URL=http://scraper:8080
      - TEXTANALYZER_BASE_URL=http://textanalyzer:8080
      - SCHEDULER_BASE_URL=http://scheduler:8080
      # Controller configuration
      - CONTROLLER_PORT=8080
      # PostgreSQL configuration
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_USER=docutag
      - DB_PASSWORD=docutag_dev_pass
      - DB_NAME=controller_db
      # Mock data generation (set to "true" to generate 14 days of test data)
      - GENERATE_MOCK_DATA=true
      # Web interface URL for footer links on static pages
      - WEB_INTERFACE_URL=http://web:3001
      # Queue configuration
      - REDIS_ADDR=redis:6379
      - WORKER_CONCURRENCY=10
      - MAX_LINK_DEPTH=1
      # Tracing
      - TEMPO_ENDPOINT=tempo:4317
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      scraper:
        condition: service_healthy
      textanalyzer:
        condition: service_healthy
      loki:
        condition: service_started
      tempo:
        condition: service_started
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    networks:
      - docutag-network
      - proxy

  # Web UI Service
  web:
    image: docutag-web:latest
    build:
      context: .
      dockerfile: apps/web/Dockerfile
      args:
        # Pass build-time arguments for Vite environment variables
        - VITE_PUBLIC_URL_BASE=http://localhost:9080
        - CONTROLLER_API_URL=http://controller:8080
        - VITE_GRAFANA_URL=http://localhost:3000/grafana
        - VITE_ASYNQ_URL=http://localhost:9084
    container_name: docutag-web
    labels:
      app: docutag
      app.type: frontend
    ports:
      - "3001:80"
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    depends_on:
      controller:
        condition: service_healthy
      loki:
        condition: service_started
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://127.0.0.1:80/"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 5s
    networks:
      - docutag-network
      - proxy

  # Scheduler Service
  scheduler:
    image: docutag-scheduler:latest
    build:
      context: .
      dockerfile: apps/scheduler/Dockerfile
    container_name: docutag-scheduler
    labels:
      app: docutag
      app.type: backend
    ports:
      - "9083:8080"
    environment:
      - PORT=8080
      # PostgreSQL configuration
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_USER=docutag
      - DB_PASSWORD=docutag_dev_pass
      - DB_NAME=scheduler_db
      - CONTROLLER_BASE_URL=http://controller:8080
      - SCRAPER_URL=http://scraper:8080
      - TEMPO_ENDPOINT=tempo:4317
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    depends_on:
      postgres:
        condition: service_healthy
      controller:
        condition: service_healthy
      scraper:
        condition: service_healthy
      loki:
        condition: service_started
      tempo:
        condition: service_started
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 5s
    networks:
      - docutag-network

  # Redis - Message queue backend
  redis:
    image: redis:7-alpine
    container_name: docutag-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes --save 60 1
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 5s
    networks:
      - docutag-network

  # Asynqmon - Queue monitoring UI
  asynqmon:
    image: hibiken/asynqmon:latest
    container_name: docutag-asynqmon
    platform: linux/amd64  # Force x86_64 for ARM64 compatibility (no ARM64 build available)
    ports:
      - "9084:8080"
    environment:
      - REDIS_ADDR=redis:6379
    command: ["--enable-metrics-exporter", "--prometheus-addr=http://prometheus:9090"]
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
      prometheus:
        condition: service_started
    networks:
      - docutag-network

  # PostgreSQL - Primary database for all services
  postgres:
    image: postgres:16-alpine
    container_name: docutag-postgres
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=docutag
      - POSTGRES_USER=docutag
      - POSTGRES_PASSWORD=docutag_dev_pass
      - PGDATA=/var/lib/postgresql/data/pgdata
      # Use dev.conf by default; override with staging.conf in production
      - POSTGRES_CONFIG_FILE=/etc/postgresql/dev.conf
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - postgres-logs:/var/log/postgresql
      - ./config/postgres/dev.conf:/etc/postgresql/dev.conf:ro
      - ./config/postgres/staging.conf:/etc/postgresql/staging.conf:ro
      - ./config/postgres/init-databases.sh:/docker-entrypoint-initdb.d/init-databases.sh:ro
    command: postgres -c config_file=/etc/postgresql/dev.conf
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U docutab -d docutab"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - docutag-network
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # PostgreSQL Exporter - Export PostgreSQL metrics to Prometheus
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: docutag-postgres-exporter
    ports:
      - "9187:9187"
    environment:
      - DATA_SOURCE_NAME=postgresql://docutag:docutag_dev_pass@postgres:5432/docutag?sslmode=disable
      - PG_EXPORTER_EXTEND_QUERY_PATH=/etc/postgres_exporter/queries.yaml
    volumes:
      - ./config/postgres/exporter-queries.yaml:/etc/postgres_exporter/queries.yaml:ro
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - docutag-network
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # Loki - Log aggregation
  loki:
    image: grafana/loki:3.0.0
    container_name: docutag-loki
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - loki-data:/loki
      - ./config/loki-config.yaml:/etc/loki/local-config.yaml
    restart: unless-stopped
    networks:
      - docutag-network

  # Promtail - Log collector for Loki
  promtail:
    image: grafana/promtail:3.0.0
    container_name: docutag-promtail
    volumes:
      - ./config/promtail:/etc/promtail
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - postgres-logs:/var/log/postgresql:ro
    command: -config.file=/etc/promtail/promtail-config-dev.yaml
    restart: unless-stopped
    depends_on:
      - loki
      - postgres
    networks:
      - docutag-network

  # Tempo - Distributed tracing
  tempo:
    image: grafana/tempo:latest
    container_name: docutag-tempo
    command: [ "-config.file=/etc/tempo.yaml" ]
    ports:
      - "3200:3200"   # Tempo
      - "4317:4317"   # OTLP gRPC
      - "4318:4318"   # OTLP HTTP
    volumes:
      - tempo-data:/var/tempo
      - ./config/tempo-config.yaml:/etc/tempo.yaml
    restart: unless-stopped
    networks:
      - docutag-network

  # Grafana - Observability dashboard
  grafana:
    image: grafana/grafana:11.0.0
    container_name: docutag-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=true
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_SECURITY_ADMIN_USER=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./config/grafana/provisioning:/etc/grafana/provisioning
    restart: unless-stopped
    depends_on:
      - loki
      - tempo
    networks:
      - docutag-network

  # Prometheus - Metrics collection and monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: docutag-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus:/etc/prometheus
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    networks:
      - docutag-network
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    depends_on:
      - loki

  # Node Exporter - System and Docker volume metrics
  node-exporter:
    image: prom/node-exporter:latest
    container_name: docutag-node-exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    restart: unless-stopped
    networks:
      - docutag-network

volumes:
  scraper-storage:
    driver: local
  redis-data:
    driver: local
  postgres-data:
    driver: local
  postgres-logs:
    driver: local
  loki-data:
    driver: local
  tempo-data:
    driver: local
  grafana-data:
    driver: local
  prometheus-data:
    driver: local

networks:
  docutag-network:
    name: docutag-network
    driver: bridge
  proxy:
    name: proxy
    external: true